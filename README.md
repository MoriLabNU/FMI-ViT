This repository contains the official implementation of our paper:
**Domain-Specific Pretraining and Fine-Tuning with Contrastive Learning for Fluorescence Microscopic Image Segmentation**  

<p align="center">
  <img src="assets/FMI.png" alt="Results" width="80%">
</p>

## ðŸš€ Highlights
- **Domain-specific pretraining**: Vision Transformer pretrained on fluorescence microscopy images.  
- **Cross-image foreground-background contrastive learning**: Improves semantic boundary recognition and cross-dataset generalization.  
- **State-of-the-art performance**: Significant IoU and Dice gains over baselines, including on unseen biomarkers.  

## ðŸ“‚ Repository Structure
â”œâ”€â”€ configs/ # Configuration files for training & evaluation
â”œâ”€â”€ datasets/ # Dataset preparation scripts
â”œâ”€â”€ models/ # Model architecture (ViT backbone + segmentation head)
â”œâ”€â”€ weights/ # Pretrained weights
â”œâ”€â”€ utils/ # Helper functions (training, evaluation, visualization)
â”œâ”€â”€ train.py # Training script
â”œâ”€â”€ evaluate.py # Evaluation script
â””â”€â”€ README.md


## ðŸ“Š Dataset Preparation
Prepare fluorescence microscopy datasets as described in the paper.

- **Dataset A**: [Download Link / Preparation Instructions](link_to_dataset_A)  
- **Dataset B**: [Download Link / Preparation Instructions](link_to_dataset_B)

## ðŸ’» Training

### **1. Pretraining (Domain-specific Self-supervised Learning)**
```
python train.py --config configs/pretrain.yaml
```

### **2. Fine-tuning (Foreground-Background Contrastive Learning)**
```
python train.py --config configs/fine_tune.yaml --pretrained weights/pretrained_vit.pth
```

### **3. Evaluation**
```
python train.py --config configs/fine_tune.yaml --pretrained weights/pretrained_vit.pth
```

## ðŸ“¥ Pretrained Weights
Pretrained weights and fine-tuned models can be downloaded here:
Pretrained ViT (Domain-specific)
Fine-tuned Model (Contrastive Learning)

## ðŸ“œ Citation
If you use this repository or our pretrained weights, please cite:

